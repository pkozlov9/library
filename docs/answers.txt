1. Структура - lb_structure.sql, данные - lb_data.sql.
Считаем сколько места на диске займёт спроектированная БД:

lb_reader

rd_id               BIGINT          8 байт
rd_full_name        CHAR(255)     256 байт
rd_date             DATETIME        8 байт
rd_created_at       DATETIME        8 байт
rd_updated_at       DATETIME        8 байт

итого                             288 байт
25 000 000 записей               6.07 гигабайт

lb_writer

wt_id                  BIGINT       8 байт
wt_full_name           CHAR(255)  256 байт
wt_date                DATETIME     8 байт
wt_reader_counter      INT          4 байта
wt_created_at          DATETIME     8 байт
wt_updated_at          DATETIME     8 байт

итого                            292 байт
25 000 000 записей              6.79 гигабайт

lb_book

bk_id                  BIGINT       8 байт
bk_rd_id               BIGING       8 байт
bk_title               CHAR(255)  256 байт
bk_date                DATETIME	    8 байт
bk_writer_counter      INT          4 байта
bk_created_at          DATETIME     8 байт
bk_updated_at          DATETIME     8 байт

итого                             300 байт
60 000 000 rows                 16.76 гигабайт

lb_writer_book

wb_wt_id               BIGINT       8 байт
wb_bk_id               BIGINT       8 байт

итого                              16 байт
60 000 000 записей               0.89 гигабайт

всего                           29.57 гигабайт

Учитывая индексы и рост данных, даже если объём данных вырастет в 10 раз 295 GB вполне уместятся на один сервер,
поэтому шардирование не применяем, ограничиваемся партиционированием.
Я использовал партиционирование во всех таблицах по id как самый простой быстрореализуемый вариант. В зависимости
от будущего интерефейса сайта и соответственно будущих запросов к БД можно изменить параметры партиционирования.
Чтобы проверить уникальность данных в каждой таблице ввёл дату рождения/издания, т к сгенерировать несколько
миллионов просто уникальных имен/названий задача непростая. 25 и 60 млн записей сгенерировал но в дамп
включать не стал, ограничился 10 тысячами. Конфиг бенератора и процедуры включил в репозиторий и дамп.
Консистентность данных поддерживается триггерами.

2. При решении подобных задач, я обычно реализую представления в БД и CRUD в Yii у меня генерируется очень быстро
автоматически практически без правок PHP кода. В этот раз так делать не стал чтобы продемонстрировать умение работать
со стандартными средствами Yii (ActiveRecord, классами GridView, DetailView и т. д.).

3. Запросы согласно моей структе БД:
3.1. SELECT bk_id, bk_title, bk_date, bk_writer_counter FROM `lb_book` WHERE bk_rd_id IS NOT NULL AND
bk_writer_counter>=3;
3.2. SELECT wt_id, wt_full_name, wt_date, wt_reader_counter FROM `lb_writer` WHERE wt_reader_counter>3;
3.3. CALL lb_random_book(5);
В хранимой процедуре lb_random_book реализован следующий алгоритм:
а. смотрим текущее значение auto_increment в таблице с книгами;
б. генерируем 5 случайных целых чисел в диапазоне от 1 до значения auto_increment'а.
в. выбираем из таблицы книг строки с id равным целым числам которые мы сгенерировали в п. б;
г. если в п. в мы получили меньше 5 строк повторяем все действия начиная с п. б, накапливаем найденные книги пока
не наберём нужное количество - 5.
Можно оптимизировать генерируя в п. б. не 5 случайных id'шников а например 100. Предложенное решение будет работать
быстро пока INSERT'ов в табицу с книгами было больше чем DELETE'ов и в ней большое количество записей.
Например при тестировании на 10000 строк простой ORDER BY RAND() LIMIT 5 значительно обыгрывал мой агоритм по времени,
однако на 60 млн. записей я так и не дождался пока выполнится ORDER BY RAND(), а моя хранимая процедура по прежнему
выдаёт результат за несколько миллисекунд. 